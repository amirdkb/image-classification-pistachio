{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import neccessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import cv2\n",
    "import torch\n",
    "from torch.utils.data import DataLoader , Dataset \n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_directory = os.getcwd()\n",
    "os.chdir(current_directory)\n",
    "datapath = r'Dataset\\Pistachio_Image_Dataset\\Pistachio_Image_Dataset'\n",
    "subfolder = os.listdir(datapath)\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "for sub in subfolder:\n",
    "    label = subfolder.index(sub)\n",
    "    path = os.path.join(datapath,sub)\n",
    "    for img_path in os.listdir(path):\n",
    "        image = cv2.imread(os.path.join(path,img_path))\n",
    "        images.append(image)\n",
    "        labels.append(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataprep(Dataset):\n",
    "    def __init__(self, features, labels, transforms=None):\n",
    "        \"\"\"\n",
    "        Initialize the Dataprep dataset.\n",
    "\n",
    "        Args:\n",
    "            features (list): List of input data (e.g., images).\n",
    "            labels (list): List of corresponding labels for the input data.\n",
    "            transforms (callable, optional): Optional transforms to be applied to the input data. Defaults to None.\n",
    "        \"\"\"\n",
    "        self.features = features  \n",
    "        self.labels = labels  \n",
    "        self.transforms = transforms  \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Get a sample from the dataset at the specified index.\n",
    "\n",
    "        Args:\n",
    "            index (int): Index of the sample to retrieve.\n",
    "\n",
    "        Returns:\n",
    "            tuple: A tuple containing the input data and its corresponding label.\n",
    "        \"\"\"\n",
    "        image = self.features[index]  \n",
    "        label = self.labels[index]  \n",
    "        if self.transforms:  \n",
    "            image = self.transforms(image)  \n",
    "\n",
    "        return image, label  \n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Get the total number of samples in the dataset.\n",
    "\n",
    "        Returns:\n",
    "            int: Total number of samples in the dataset.\n",
    "        \"\"\"\n",
    "        return len(self.labels)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = transforms.Compose([transforms.ToTensor(), transforms.Resize((200,200))])\n",
    "dataset = Dataprep(images,labels,data_transforms)\n",
    "# data_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "# data_sample = next(iter(data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "# X_test, X_val = train_test_split(X_test_val, test_size=0.5, random_state=42)\n",
    "train_loader = DataLoader(X_train, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(X_test, batch_size=32, shuffle=True)\n",
    "# val_loader = DataLoader(X_val, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pistachiomodel(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize the Pistachiomodel neural network architecture.\n",
    "        \"\"\"\n",
    "        super(Pistachiomodel, self).__init__()\n",
    "        \n",
    "        # Define the layers of the neural network\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=2, stride=2, padding=0)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.linear = nn.Linear(64*50*50, 2)  # Output layer with 2 classes\n",
    "\n",
    "    def forward(self, data):\n",
    "        \"\"\"\n",
    "        Define the forward pass of the neural network.\n",
    "\n",
    "        Args:\n",
    "            data (torch.Tensor): Input data to the neural network.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output of the neural network.\n",
    "        \"\"\"\n",
    "        # Forward pass through the network layers\n",
    "        data = self.conv1(data)  # Apply convolutional layer\n",
    "        data = self.maxpool(data)  # Apply max pooling layer\n",
    "        data = self.activation(data)  # Apply ReLU activation function\n",
    "        data = self.flatten(data)  # Flatten the data\n",
    "        data = self.dropout(data)  # Apply dropout regularization\n",
    "        data = self.linear(data)  # Apply fully connected layer\n",
    "\n",
    "        return data  # Return the output of the neural network\n",
    "\n",
    "# Move model to device (GPU if available, otherwise CPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Create an instance of the Pistachiomodel neural network\n",
    "model = Pistachiomodel().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50 || Loss: 1.1943 || Accuracy: 52.33%\n",
      "Epoch: 2/50 || Loss: 0.6314 || Accuracy: 54.05%\n",
      "Epoch: 3/50 || Loss: 0.5486 || Accuracy: 58.48%\n",
      "Epoch: 4/50 || Loss: 0.5861 || Accuracy: 63.21%\n",
      "Epoch: 5/50 || Loss: 0.4207 || Accuracy: 65.77%\n",
      "Epoch: 6/50 || Loss: 0.3048 || Accuracy: 67.98%\n",
      "Epoch: 7/50 || Loss: 0.5277 || Accuracy: 69.63%\n",
      "Epoch: 8/50 || Loss: 0.3918 || Accuracy: 71.09%\n",
      "Epoch: 9/50 || Loss: 0.5131 || Accuracy: 72.36%\n",
      "Epoch: 10/50 || Loss: 0.4310 || Accuracy: 73.38%\n",
      "Epoch: 11/50 || Loss: 0.3589 || Accuracy: 74.18%\n",
      "Epoch: 12/50 || Loss: 0.3344 || Accuracy: 74.84%\n",
      "Epoch: 13/50 || Loss: 0.3246 || Accuracy: 75.46%\n",
      "Epoch: 14/50 || Loss: 0.3525 || Accuracy: 75.94%\n",
      "Epoch: 15/50 || Loss: 0.4096 || Accuracy: 76.42%\n",
      "Epoch: 16/50 || Loss: 0.4645 || Accuracy: 76.84%\n",
      "Epoch: 17/50 || Loss: 0.2508 || Accuracy: 77.18%\n",
      "Epoch: 18/50 || Loss: 0.2592 || Accuracy: 77.57%\n",
      "Epoch: 19/50 || Loss: 0.3834 || Accuracy: 77.86%\n",
      "Epoch: 20/50 || Loss: 0.2848 || Accuracy: 78.18%\n",
      "Epoch: 21/50 || Loss: 0.4912 || Accuracy: 78.45%\n",
      "Epoch: 22/50 || Loss: 0.3576 || Accuracy: 78.67%\n",
      "Epoch: 23/50 || Loss: 0.4879 || Accuracy: 78.91%\n",
      "Epoch: 24/50 || Loss: 0.3271 || Accuracy: 79.13%\n",
      "Epoch: 25/50 || Loss: 0.4829 || Accuracy: 79.33%\n",
      "Epoch: 26/50 || Loss: 0.3295 || Accuracy: 79.52%\n",
      "Epoch: 27/50 || Loss: 0.4825 || Accuracy: 79.69%\n",
      "Epoch: 28/50 || Loss: 0.3864 || Accuracy: 79.87%\n",
      "Epoch: 29/50 || Loss: 0.2979 || Accuracy: 80.00%\n",
      "Epoch: 30/50 || Loss: 0.3418 || Accuracy: 80.11%\n",
      "Epoch: 31/50 || Loss: 0.2977 || Accuracy: 80.26%\n",
      "Epoch: 32/50 || Loss: 0.3680 || Accuracy: 80.42%\n",
      "Epoch: 33/50 || Loss: 0.4430 || Accuracy: 80.57%\n",
      "Epoch: 34/50 || Loss: 0.3259 || Accuracy: 80.69%\n",
      "Epoch: 35/50 || Loss: 0.2975 || Accuracy: 80.81%\n",
      "Epoch: 36/50 || Loss: 0.3999 || Accuracy: 80.91%\n",
      "Epoch: 37/50 || Loss: 0.3634 || Accuracy: 81.02%\n",
      "Epoch: 38/50 || Loss: 0.2744 || Accuracy: 81.12%\n",
      "Epoch: 39/50 || Loss: 0.4364 || Accuracy: 81.23%\n",
      "Epoch: 40/50 || Loss: 0.3169 || Accuracy: 81.34%\n",
      "Epoch: 41/50 || Loss: 0.2628 || Accuracy: 81.44%\n",
      "Epoch: 42/50 || Loss: 0.3782 || Accuracy: 81.54%\n",
      "Epoch: 43/50 || Loss: 0.4294 || Accuracy: 81.61%\n",
      "Epoch: 44/50 || Loss: 0.5232 || Accuracy: 81.71%\n",
      "Epoch: 45/50 || Loss: 0.3414 || Accuracy: 81.78%\n",
      "Epoch: 46/50 || Loss: 0.3462 || Accuracy: 81.87%\n",
      "Epoch: 47/50 || Loss: 0.4024 || Accuracy: 81.94%\n",
      "Epoch: 48/50 || Loss: 0.3792 || Accuracy: 82.01%\n",
      "Epoch: 49/50 || Loss: 0.2722 || Accuracy: 82.09%\n",
      "Epoch: 50/50 || Loss: 0.2981 || Accuracy: 82.14%\n"
     ]
    }
   ],
   "source": [
    "# Define the learning rate and number of epochs\n",
    "learning_rate = 0.001\n",
    "epochs = 50\n",
    "\n",
    "# Define the optimizer and loss function\n",
    "optimizer = optim.SGD(model.parameters(), learning_rate)  # Stochastic Gradient Descent optimizer\n",
    "criterion = nn.CrossEntropyLoss()  # Cross-entropy loss function\n",
    "\n",
    "# Initialize variables to track total samples and correct predictions\n",
    "total_sample = 0\n",
    "total_correct = 0\n",
    "\n",
    "# Iterate over the specified number of epochs\n",
    "for i in range(epochs):\n",
    "    # Iterate over batches of data in the training loader\n",
    "    for image, target in train_loader:\n",
    "        # Move input data and target labels to the appropriate device (GPU or CPU)\n",
    "        image = image.to(device)\n",
    "        target = target.to(device)\n",
    "        \n",
    "        # Zero the gradients accumulated in the optimizer\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(image)\n",
    "        \n",
    "        # Compute predicted labels by finding the maximum value along dimension 1\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        \n",
    "        # Update total sample count and correct prediction count\n",
    "        total_sample += target.size(0)\n",
    "        total_correct += (predicted == target).sum().item()\n",
    "        \n",
    "        # Calculate the loss between the predicted outputs and target labels\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        # Backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        \n",
    "        # Perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "\n",
    "    # Calculate accuracy for the current epoch\n",
    "    accuracy = total_correct / total_sample\n",
    "    \n",
    "    # Print epoch number, loss, and accuracy\n",
    "    print(f'Epoch: {i+1}/{epochs} || Loss: {loss.item():.4f} || Accuracy: {accuracy:.2%}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 82.33%\n"
     ]
    }
   ],
   "source": [
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Initialize variables to track correct predictions and total samples\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# Disable gradient calculation during inference\n",
    "with torch.no_grad():\n",
    "    # Iterate over batches of data in the test loader\n",
    "    for images, targets in test_loader:\n",
    "        # Move input data and target labels to the appropriate device (GPU or CPU)\n",
    "        images = images.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        # Forward pass: compute predicted outputs by passing inputs to the model\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Compute predicted labels by finding the maximum value along dimension 1\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        # Update total sample count and correct prediction count\n",
    "        total += targets.size(0)\n",
    "        correct += (predicted == targets).sum().item()\n",
    "\n",
    "# Calculate test accuracy\n",
    "test_accuracy = correct / total\n",
    "\n",
    "# Print test accuracy\n",
    "print(f'Test Accuracy: {test_accuracy:.2%}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
